---
title: "Model Selection"
author: "Benjamin"
date: "2019-03-31"
description: ""
featuredImage: ""
slug: model-selection
tags: []
categories: R
---

First post (hopefully I get the file links right). I"ll be walking through the following worked example: https://medium.com/@peter.nistrup/model-selection-101-using-r-c8437b5f9f99

## 1. Create a base-model using all available variables and data
The objective here is to develop a model that predicts female employment status based on citizenship status, availability of government support, and demogrpahic characteristics.

| Variable | Description |
| --- | --- |
| employed | Employment Status (y/n) |
| foreigner | Foreigner (y/n) |
| gov.support | Amount of Government entitled support (log-transformed) |
| age | Age |
| education | Years of Schooling (continuous) |
| young.children | No. of Young Children |
| school.children | No. of School-aged Children |

```{r, echo = FALSE, results = "hide", warning = FALSE, error = FALSE, message = FALSE}
library(tidyverse)
library(GGally)
data <- read.csv("~/Documents/R/website/content/data/employment_data.txt", sep="", header = TRUE)

names(data) <- c("employed", "foreigner", "gov.support", "age", "education", "young.children", "school.children")
levels(data$employed)[1] <- "yes"
levels(data$employed)[2] <- "no"
levels(data$foreigner)[1] <- "yes"
levels(data$foreigner)[2] <- "no"
```

```{r, warning = FALSE, error = FALSE, message = FALSE}
str(data)
summary(data)

graph_corr1 <- ggpairs(data, mapping = aes(color = employed), columns = c("employed", "foreigner", "gov.support", "age", "education", "young.children", "school.children"), columnLabels = c("employed", "foreigner", "gov.support", "age", "education", "young.children", "school.children"), legend = c(1,1)) +
  theme_minimal()

graph_corr2 <- ggpairs(data,columns = c("employed", "foreigner", "gov.support", "age", "education", "young.children", "school.children"), columnLabels = c("employed", "foreigner", "gov.support", "age", "education", "young.children", "school.children")) +
  theme_minimal()

graph_corr1
graph_corr2
```

```{r}
fit.lm1 <- glm(employed == "yes" ~., data = data, family = binomial())
summary(fit.lm1)
```

## 2. Factorize categorical variables if R didn"t do the job

There is a chance that there is a categorical difference between having no children, and having at least one child (See code below). The simple transformation improves AIC too <insert AIC reading>

```{r}
tempfit <- update(fit.lm1, .~. + factor(young.children ==0)
                               + factor(school.children ==0)
                               + factor(young.children + school.children ==0))
summary(tempfit)
```

## 3. Add relevant power-transformations

The next question is whether we should add any squared or cubed terms into the model. One way to eyeball if this is necessary is to fit a non-parametric model (the version below uses the Nadaraya-Watson kernel regression estimate), and check if the non-parametric line seems to suggest if a quadratic or cubic fit is necessary. In this case, we do so over a range of 'bandwidth'.

### To-do: Read up more about non-parametric models! 

```{r}
logit.plot <- function(x, y, h, link="logit", xlab=deparse(substitute(x)), yname=deparse(substitute(y)), ylab, rug=T, data, ... ) {
  
    if(!missing(data)){
        call <- match.call()
        dataPos <- match("data",names(call))
        return(invisible(with(data, eval(call[-dataPos]))))
    }
  
    if (length(levels(factor(y)))!=2) stop("y must be binary")
    succes <- levels(factor(y))[2]

    if (missing(ylab)) ylab <- paste(binomial(link)$link," P{",yname,"=",succes,"|",xlab,"}", sep="", collapse="")
    
    if (is.factor(y)) y <- as.numeric(y==levels(y)[2])
    x.seq <- seq(min(x),max(x),length=101)
    smooth <- binomial(link)$linkfun(ksmooth(x, y, "normal", h, x.points=x.seq)$y)
    plot(smooth~x.seq, ylab=ylab, xlab=xlab, type="l", ...)
    
    if (rug) rug(x)
    invisible(xy.coords(x = x.seq, y = smooth, xlab = xlab, ylab = ylab))
}

for(i in seq(2.5,10,length.out = 6)) {
  logit.plot(x = age, y = employed == 'yes', h = i, data = data, main = paste0("bandwidth = ",i)) }

for(i in seq(2.5,10,length.out = 6)) {
    logit.plot(x = education, y = employed == 'yes', h = i, data = data, main = paste0("bandwidth = ",i)) }

for(i in seq(2.5,10,length.out = 6)) {
    logit.plot(x = gov.support, y = employed == 'yes', h = i, data = data, main = paste0("bandwidth = ",i)) }

tempfit <- update(tempfit, .~. + I(age^2) 
                               + I(education^2)
                               + I(education^3)
                               + I(gov.support^2))
summary(tempfit)
fit.2 <- tempfit


```

Add relevant variable interaction

```{r}
add1.test <- add1(fit.2, scope = .~. + .^2, test="Chisq")
add1.test[order(add1.test$'Pr(>Chi)'),]

add1.test <- add1(update(fit.2, .~. + foreigner:age), scope = .~. + .^2, test="Chisq")
add1.test[order(add1.test$'Pr(>Chi)'),]
```

Remove insignificant variables with relevant testing criteria
- Repeat step 3â€“5 until you"ve exhausted your options
Remove any outlying datapoints
Evaluate your model
Visualizing your findings